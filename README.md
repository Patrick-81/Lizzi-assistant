# ğŸŒŸ Lizzi - Assistant Personnel Intelligent

Assistant personnel local alimentÃ© par IA avec capacitÃ©s vocales et mÃ©moire long terme.

## FonctionnalitÃ©s

- ğŸ’¬ Chat conversationnel avec interface web Ã©lÃ©gante
- ğŸ—£ï¸ SynthÃ¨se vocale (Text-to-Speech) avec Piper
- ğŸ§  MÃ©moire long terme avec gestion des faits
- ğŸ§® Outils de calcul mathÃ©matique avancÃ©
- ğŸ“… Manipulation de dates et conversions d'unitÃ©s
- ğŸ¨ Affichage Markdown des rÃ©ponses
- ğŸ”’ 100% local - vos donnÃ©es restent privÃ©es

## PrÃ©requis

- Node.js 18+
- Ollama avec un modÃ¨le LLM (mistral, qwen, llama, etc.)
- Piper pour la synthÃ¨se vocale
- GPU recommandÃ© (testÃ© avec RTX 3060 12GB)

## Installation

1. Clone le repo
2. Configure `.env` avec l'hÃ´te Ollama et le modÃ¨le
3. `npm install`
4. `npm run dev`
5. AccÃ¨de Ã  `http://localhost:3001`

## Architecture

- **Backend** : Node.js + Express + TypeScript
- **LLM** : Ollama (flexible, n'importe quel modÃ¨le)
- **TTS** : Piper (synthÃ¨se vocale locale)
- **Frontend** : HTML/CSS/JS vanilla avec Markdown
- **MÃ©moire** : JSON pour les faits long terme

## Configuration

Fichier `.env` :
```
OLLAMA_HOST=http://localhost:11434
MODEL_NAME=qwen2.5:14b
PORT=3001
```

## Licence

MIT
